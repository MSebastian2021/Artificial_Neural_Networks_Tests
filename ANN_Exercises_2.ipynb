{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Exercises_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNm3zdV+DdXHIQ6CNj/Exuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSebastian2021/Artificial_Neural_Networks_Tests/blob/main/ANN_Exercises_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOHY7xis-rw-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7sCEyXj_A1M",
        "outputId": "54cd9098-f835-4aea-c538-fb347ba53f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a prediction whether a customer will exit the bank or not\n",
        "**Exited** is the label column"
      ],
      "metadata": {
        "id": "UKZ0DiwfBa0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ANN_test_data/Churn_Modelling.csv')\n",
        "#Kaggle database (source: https://colab.research.google.com/drive/#create=1&folderId=0ADeqHwPhnbKbUk9PVA)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "zSsStJD8_Nkm",
        "outputId": "1e424406-992f-4963-a919-54fce3eb52dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d838b91d-05a5-40b6-b941-f6f677c2c3de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d838b91d-05a5-40b6-b941-f6f677c2c3de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d838b91d-05a5-40b6-b941-f6f677c2c3de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d838b91d-05a5-40b6-b941-f6f677c2c3de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
              "0             1    15634602   Hargrave          619    France  Female   42   \n",
              "1             2    15647311       Hill          608     Spain  Female   41   \n",
              "2             3    15619304       Onio          502    France  Female   42   \n",
              "3             4    15701354       Boni          699    France  Female   39   \n",
              "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
              "...         ...         ...        ...          ...       ...     ...  ...   \n",
              "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
              "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
              "9997       9998    15584532        Liu          709    France  Female   36   \n",
              "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
              "9999      10000    15628319     Walker          792    France  Female   28   \n",
              "\n",
              "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0          2       0.00              1          1               1   \n",
              "1          1   83807.86              1          0               1   \n",
              "2          8  159660.80              3          1               0   \n",
              "3          1       0.00              2          0               0   \n",
              "4          2  125510.82              1          1               1   \n",
              "...      ...        ...            ...        ...             ...   \n",
              "9995       5       0.00              2          1               0   \n",
              "9996      10   57369.61              1          1               1   \n",
              "9997       7       0.00              1          0               1   \n",
              "9998       3   75075.31              2          1               0   \n",
              "9999       4  130142.79              1          1               0   \n",
              "\n",
              "      EstimatedSalary  Exited  \n",
              "0           101348.88       1  \n",
              "1           112542.58       0  \n",
              "2           113931.57       1  \n",
              "3            93826.63       0  \n",
              "4            79084.10       0  \n",
              "...               ...     ...  \n",
              "9995         96270.64       0  \n",
              "9996        101699.77       0  \n",
              "9997         42085.58       1  \n",
              "9998         92888.52       1  \n",
              "9999         38190.78       0  \n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6KZaiGNCykd",
        "outputId": "3fc2f73e-3146-4219-ef59-2ed109c63c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
              "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
              "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "display the number of rows:"
      ],
      "metadata": {
        "id": "Iv8He_b0DN_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlMksI7uDBGr",
        "outputId": "d1176079-13e3-4e9e-f191-37d3c9c8c810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=10000, step=1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a variable to hold dataset columns from 3 to 13\n",
        "x = dataset.iloc[:, 3: 13].values\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dRcaiZNDFUf",
        "outputId": "f4afa764-8e6b-43f2-9335-65379aff96c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#store the labels to array variable, y\n",
        "y = dataset.iloc[:, 13].values\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAIlZlVvET5r",
        "outputId": "7f99f4aa-b980-4854-8e4e-b14051fc03e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode text values using ordinal encoding (column 1: Geography, and column 2: Coding)\n",
        "First method: **Ordinal encoding** is used when the order of the values is important"
      ],
      "metadata": {
        "id": "RvjDWegjFpay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "qdzchLYSFMJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ord_1 = dataset.iloc[:, 3: 13].values\n",
        "\n",
        "labelencoder_x = LabelEncoder() #instantiate an object of the class LabelEncoder\n",
        "x_ord_1[:, 1] = labelencoder_x.fit_transform(x_ord_1[:, 1]) #ordinal encoding for col 1\n",
        "x_ord_1[:, 2] = labelencoder_x.fit_transform(x_ord_1[:, 2]) #ordinal encoding for col 2\n",
        "\n",
        "x_ord_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd76cfb-bc63-4df4-ebdc-4e0aa64df6ea",
        "id": "PjmK7ZvPLQu_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
              "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
              "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
              "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
              "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ORDINAL ENCODING - 2nd way (Bug - sets all values to 0)"
      ],
      "metadata": {
        "id": "LEPDU40TM6gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "metadata": {
        "id": "1rbJCGN0LeAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_ord_2 = dataset.iloc[:, 3: 13].values\n",
        "\n",
        "ordinal_encoder_1 = OrdinalEncoder() #instantiate an object of the class LabelEncoder\n",
        "x_ord_2[:, 1] = ordinal_encoder_1.fit_transform([x_ord_2[:, 1]])\n",
        "x_ord_2[:, 2] = ordinal_encoder_1.fit_transform([x_ord_2[:, 2]]) #ordinal encoding for col 1\n",
        "\n",
        "x_ord_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e47230-e2f5-4e35-f7ea-d943b2ac194e",
        "id": "LQy7EQwVLNXT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
              "       [608, 0.0, 0.0, ..., 0, 1, 112542.58],\n",
              "       [502, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
              "       [772, 0.0, 0.0, ..., 1, 0, 92888.52],\n",
              "       [792, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One Hot Encoding Method"
      ],
      "metadata": {
        "id": "Uj0bQQkMNKDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "rAcnVmQsNR2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the ordinally-converted data\n",
        "x  = x_ord_1\n",
        "\n",
        "# encoder is the column transformer\n",
        "# the column numbers to be tranformed here is [1] but can be [1, 1, 3]\n",
        "ct = ColumnTransformer([('encoder', OneHotEncoder(), [1])], \n",
        "                       remainder='passthrough') # leave the rest of the column untouched\n",
        "\n",
        "x = np.array(ct.fit_transform(x), dtype = np.int)\n",
        "df = pd.DataFrame(x)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "6ZxRFSugNpsk",
        "outputId": "24fe25e6-2ce2-4234-b594-31b182cd1d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c7f806f-fae1-4bf0-813b-4be361b18693\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>771</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>516</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c7f806f-fae1-4bf0-813b-4be361b18693')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c7f806f-fae1-4bf0-813b-4be361b18693 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c7f806f-fae1-4bf0-813b-4be361b18693');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0   1   2    3   4   5   6       7   8   9   10      11\n",
              "0      1   0   0  619   0  42   2       0   1   1   1  101348\n",
              "1      0   0   1  608   0  41   1   83807   1   0   1  112542\n",
              "2      1   0   0  502   0  42   8  159660   3   1   0  113931\n",
              "3      1   0   0  699   0  39   1       0   2   0   0   93826\n",
              "4      0   0   1  850   0  43   2  125510   1   1   1   79084\n",
              "...   ..  ..  ..  ...  ..  ..  ..     ...  ..  ..  ..     ...\n",
              "9995   1   0   0  771   1  39   5       0   2   1   0   96270\n",
              "9996   1   0   0  516   1  35  10   57369   1   1   1  101699\n",
              "9997   1   0   0  709   0  36   7       0   1   0   1   42085\n",
              "9998   0   1   0  772   1  42   3   75075   2   1   0   92888\n",
              "9999   1   0   0  792   0  28   4  130142   1   1   0   38190\n",
              "\n",
              "[10000 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we remove the first column to avoid the dumm data trap\n",
        "Dummy data trap: a scenario where in dependent variables are highly correlated ( one variable predicts the value of the others)\n",
        "In one hot enoding, one dummy variable can be predicted through dummy variables, causing redundancy\n",
        "\n",
        "Using all dummy variables in One hot encoding cause dummy trap in regression models\n"
      ],
      "metadata": {
        "id": "7O3ucbo8T0KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=x[:, 1:]\n",
        "df = pd.DataFrame(x)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PwKnIdiLTiL5",
        "outputId": "94ad4685-7fae-437a-c2b9-f633bf8fbb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e6251d0c-cef7-4bd2-88ca-7e0898774b74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>771</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>516</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6251d0c-cef7-4bd2-88ca-7e0898774b74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6251d0c-cef7-4bd2-88ca-7e0898774b74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6251d0c-cef7-4bd2-88ca-7e0898774b74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0   1    2   3   4   5       6   7   8   9       10\n",
              "0      0   0  619   0  42   2       0   1   1   1  101348\n",
              "1      0   1  608   0  41   1   83807   1   0   1  112542\n",
              "2      0   0  502   0  42   8  159660   3   1   0  113931\n",
              "3      0   0  699   0  39   1       0   2   0   0   93826\n",
              "4      0   1  850   0  43   2  125510   1   1   1   79084\n",
              "...   ..  ..  ...  ..  ..  ..     ...  ..  ..  ..     ...\n",
              "9995   0   0  771   1  39   5       0   2   1   0   96270\n",
              "9996   0   0  516   1  35  10   57369   1   1   1  101699\n",
              "9997   0   0  709   0  36   7       0   1   0   1   42085\n",
              "9998   1   0  772   1  42   3   75075   2   1   0   92888\n",
              "9999   0   0  792   0  28   4  130142   1   1   0   38190\n",
              "\n",
              "[10000 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One Hot Encoding - 2nd way"
      ],
      "metadata": {
        "id": "wGimDagSQw6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_df = dataset.iloc[:, 3: 13]\n",
        "#drops the first column (France, because we do not want correlated data, \n",
        "#and we can conclude from the values of Spain and Germany the value of FRance)\n",
        "#axis=1 means to concatenate along the columns (put one col beside the other)\n",
        "x_df = pd.concat([x_df, pd.get_dummies(x_df['Geography'], prefix='country', drop_first=True)], axis=1)\n",
        "\n",
        "#get rid fo the original geography column\n",
        "x_df.drop(['Geography'], axis=1, inplace=True)\n",
        "x_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "DvEjVOJwQ381",
        "outputId": "e54c781c-e8ad-4519-e149-f3f7958cb8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7742c936-c0a2-4a43-9d60-8208f0dabf86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>country_Germany</th>\n",
              "      <th>country_Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7742c936-c0a2-4a43-9d60-8208f0dabf86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7742c936-c0a2-4a43-9d60-8208f0dabf86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7742c936-c0a2-4a43-9d60-8208f0dabf86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0             619  Female   42       2       0.00              1          1   \n",
              "1             608  Female   41       1   83807.86              1          0   \n",
              "2             502  Female   42       8  159660.80              3          1   \n",
              "3             699  Female   39       1       0.00              2          0   \n",
              "4             850  Female   43       2  125510.82              1          1   \n",
              "...           ...     ...  ...     ...        ...            ...        ...   \n",
              "9995          771    Male   39       5       0.00              2          1   \n",
              "9996          516    Male   35      10   57369.61              1          1   \n",
              "9997          709  Female   36       7       0.00              1          0   \n",
              "9998          772    Male   42       3   75075.31              2          1   \n",
              "9999          792  Female   28       4  130142.79              1          1   \n",
              "\n",
              "      IsActiveMember  EstimatedSalary  country_Germany  country_Spain  \n",
              "0                  1        101348.88                0              0  \n",
              "1                  1        112542.58                0              1  \n",
              "2                  0        113931.57                0              0  \n",
              "3                  0         93826.63                0              0  \n",
              "4                  1         79084.10                0              1  \n",
              "...              ...              ...              ...            ...  \n",
              "9995               0         96270.64                0              0  \n",
              "9996               1        101699.77                0              0  \n",
              "9997               1         42085.58                0              0  \n",
              "9998               0         92888.52                1              0  \n",
              "9999               0         38190.78                0              0  \n",
              "\n",
              "[10000 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into training and test set (20% for the test set)"
      ],
      "metadata": {
        "id": "R0X6Q6rVUqAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#we use the random_state to make sure the splitting contains \n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "aMJlsbeJUxOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardize the data (xstandardised = (x - x_mean)/std_dev"
      ],
      "metadata": {
        "id": "kXR-eAsbVFDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "x_train = sc.fit_transform(x_train)\n",
        "#we use the scale set from the training set to transform the test set\n",
        "x_test = sc.transform(x_test)\n",
        "\n",
        "df = pd.DataFrame(x_train)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "No6nKnVUVN69",
        "outputId": "58a04620-4e38-423c-80d5-1bfc59f37e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1e2b5894-ffac-4794-b210-7ac86c0bce06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.230820</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>-0.944500</td>\n",
              "      <td>-0.701742</td>\n",
              "      <td>0.588164</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>0.427402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.251509</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>-0.944500</td>\n",
              "      <td>-0.355203</td>\n",
              "      <td>0.469851</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>-1.025493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.396330</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>0.774987</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.858782</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.944793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.044622</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>1.252622</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.565605</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.551941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>1.746019</td>\n",
              "      <td>0.658795</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>-0.562392</td>\n",
              "      <td>1.030954</td>\n",
              "      <td>0.730400</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>1.083388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.303231</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>0.774987</td>\n",
              "      <td>0.684415</td>\n",
              "      <td>0.495441</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.579177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>0.348464</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>2.303420</td>\n",
              "      <td>-0.701742</td>\n",
              "      <td>0.076671</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>-0.529777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>0.224332</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>0.583933</td>\n",
              "      <td>1.377494</td>\n",
              "      <td>-1.225991</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.140972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>0.131233</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>0.010771</td>\n",
              "      <td>1.030954</td>\n",
              "      <td>-1.225991</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>0.017805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>1.165670</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>0.297352</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.379950</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>-1.158233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e2b5894-ffac-4794-b210-7ac86c0bce06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e2b5894-ffac-4794-b210-7ac86c0bce06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e2b5894-ffac-4794-b210-7ac86c0bce06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "0     1.714901 -0.572731 -0.230820  0.915091 -0.944500 -0.701742  0.588164   \n",
              "1    -0.583124 -0.572731 -0.251509 -1.092788 -0.944500 -0.355203  0.469851   \n",
              "2     1.714901 -0.572731 -0.396330 -1.092788  0.774987  0.337876  0.858782   \n",
              "3     1.714901 -0.572731 -0.044622 -1.092788  1.252622  0.337876  0.565605   \n",
              "4    -0.583124  1.746019  0.658795  0.915091 -0.562392  1.030954  0.730400   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7995  1.714901 -0.572731 -0.303231  0.915091  0.774987  0.684415  0.495441   \n",
              "7996  1.714901 -0.572731  0.348464 -1.092788  2.303420 -0.701742  0.076671   \n",
              "7997 -0.583124 -0.572731  0.224332 -1.092788  0.583933  1.377494 -1.225991   \n",
              "7998 -0.583124 -0.572731  0.131233 -1.092788  0.010771  1.030954 -1.225991   \n",
              "7999  1.714901 -0.572731  1.165670  0.915091  0.297352  0.337876  0.379950   \n",
              "\n",
              "            7         8         9         10  \n",
              "0     0.802257 -1.553374  0.977259  0.427402  \n",
              "1     0.802257 -1.553374 -1.023271 -1.025493  \n",
              "2    -0.911510  0.643760  0.977259 -0.944793  \n",
              "3     0.802257 -1.553374  0.977259 -0.551941  \n",
              "4    -0.911510 -1.553374 -1.023271  1.083388  \n",
              "...        ...       ...       ...       ...  \n",
              "7995 -0.911510  0.643760  0.977259 -0.579177  \n",
              "7996 -0.911510  0.643760 -1.023271 -0.529777  \n",
              "7997 -0.911510  0.643760  0.977259 -0.140972  \n",
              "7998  0.802257  0.643760  0.977259  0.017805  \n",
              "7999 -0.911510  0.643760 -1.023271 -1.158233  \n",
              "\n",
              "[8000 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model, using 2 dense layers"
      ],
      "metadata": {
        "id": "a_qj87ygWfVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "#add first layer and first hidden layer, units = number of nodes / neurons\n",
        "model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "#add second hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))"
      ],
      "metadata": {
        "id": "_nhiy4I7Wll3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add the output layer (sigmoid for binary, softmax for multiclass)\n",
        "model.add(tf.keras.layers.Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
      ],
      "metadata": {
        "id": "gaGqbWJ-ZXWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compilation\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "e5XNACu_ZqQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "#no of steps has to do with the batch size (number of data points/batch size, 8000/10=800)\n",
        "#batch size should not be more than 32\n",
        "history = model.fit(x_train, y_train, batch_size=10, epochs = 200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlCndKrSaZJw",
        "outputId": "c3f0b830-7587-45ce-b4bb-c92573d43151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "800/800 - 2s - loss: 0.4885 - accuracy: 0.7965 - 2s/epoch - 3ms/step\n",
            "Epoch 2/200\n",
            "800/800 - 1s - loss: 0.4314 - accuracy: 0.7972 - 1s/epoch - 2ms/step\n",
            "Epoch 3/200\n",
            "800/800 - 1s - loss: 0.4269 - accuracy: 0.7972 - 1s/epoch - 2ms/step\n",
            "Epoch 4/200\n",
            "800/800 - 1s - loss: 0.4226 - accuracy: 0.8037 - 892ms/epoch - 1ms/step\n",
            "Epoch 5/200\n",
            "800/800 - 1s - loss: 0.4187 - accuracy: 0.8230 - 896ms/epoch - 1ms/step\n",
            "Epoch 6/200\n",
            "800/800 - 1s - loss: 0.4160 - accuracy: 0.8278 - 894ms/epoch - 1ms/step\n",
            "Epoch 7/200\n",
            "800/800 - 1s - loss: 0.4142 - accuracy: 0.8295 - 894ms/epoch - 1ms/step\n",
            "Epoch 8/200\n",
            "800/800 - 1s - loss: 0.4129 - accuracy: 0.8325 - 896ms/epoch - 1ms/step\n",
            "Epoch 9/200\n",
            "800/800 - 1s - loss: 0.4119 - accuracy: 0.8330 - 906ms/epoch - 1ms/step\n",
            "Epoch 10/200\n",
            "800/800 - 1s - loss: 0.4108 - accuracy: 0.8331 - 881ms/epoch - 1ms/step\n",
            "Epoch 11/200\n",
            "800/800 - 1s - loss: 0.4100 - accuracy: 0.8340 - 901ms/epoch - 1ms/step\n",
            "Epoch 12/200\n",
            "800/800 - 1s - loss: 0.4090 - accuracy: 0.8340 - 898ms/epoch - 1ms/step\n",
            "Epoch 13/200\n",
            "800/800 - 1s - loss: 0.4085 - accuracy: 0.8338 - 886ms/epoch - 1ms/step\n",
            "Epoch 14/200\n",
            "800/800 - 1s - loss: 0.4083 - accuracy: 0.8345 - 895ms/epoch - 1ms/step\n",
            "Epoch 15/200\n",
            "800/800 - 1s - loss: 0.4070 - accuracy: 0.8350 - 921ms/epoch - 1ms/step\n",
            "Epoch 16/200\n",
            "800/800 - 1s - loss: 0.4068 - accuracy: 0.8351 - 903ms/epoch - 1ms/step\n",
            "Epoch 17/200\n",
            "800/800 - 1s - loss: 0.4064 - accuracy: 0.8336 - 905ms/epoch - 1ms/step\n",
            "Epoch 18/200\n",
            "800/800 - 1s - loss: 0.4060 - accuracy: 0.8361 - 896ms/epoch - 1ms/step\n",
            "Epoch 19/200\n",
            "800/800 - 1s - loss: 0.4058 - accuracy: 0.8372 - 905ms/epoch - 1ms/step\n",
            "Epoch 20/200\n",
            "800/800 - 1s - loss: 0.4053 - accuracy: 0.8349 - 907ms/epoch - 1ms/step\n",
            "Epoch 21/200\n",
            "800/800 - 1s - loss: 0.4052 - accuracy: 0.8346 - 911ms/epoch - 1ms/step\n",
            "Epoch 22/200\n",
            "800/800 - 1s - loss: 0.4049 - accuracy: 0.8338 - 895ms/epoch - 1ms/step\n",
            "Epoch 23/200\n",
            "800/800 - 1s - loss: 0.4049 - accuracy: 0.8353 - 884ms/epoch - 1ms/step\n",
            "Epoch 24/200\n",
            "800/800 - 1s - loss: 0.4043 - accuracy: 0.8371 - 902ms/epoch - 1ms/step\n",
            "Epoch 25/200\n",
            "800/800 - 1s - loss: 0.4044 - accuracy: 0.8349 - 911ms/epoch - 1ms/step\n",
            "Epoch 26/200\n",
            "800/800 - 1s - loss: 0.4039 - accuracy: 0.8356 - 913ms/epoch - 1ms/step\n",
            "Epoch 27/200\n",
            "800/800 - 1s - loss: 0.4037 - accuracy: 0.8365 - 891ms/epoch - 1ms/step\n",
            "Epoch 28/200\n",
            "800/800 - 1s - loss: 0.4032 - accuracy: 0.8359 - 891ms/epoch - 1ms/step\n",
            "Epoch 29/200\n",
            "800/800 - 1s - loss: 0.4034 - accuracy: 0.8363 - 896ms/epoch - 1ms/step\n",
            "Epoch 30/200\n",
            "800/800 - 1s - loss: 0.4032 - accuracy: 0.8359 - 907ms/epoch - 1ms/step\n",
            "Epoch 31/200\n",
            "800/800 - 1s - loss: 0.4030 - accuracy: 0.8367 - 910ms/epoch - 1ms/step\n",
            "Epoch 32/200\n",
            "800/800 - 1s - loss: 0.4030 - accuracy: 0.8356 - 909ms/epoch - 1ms/step\n",
            "Epoch 33/200\n",
            "800/800 - 1s - loss: 0.4027 - accuracy: 0.8366 - 884ms/epoch - 1ms/step\n",
            "Epoch 34/200\n",
            "800/800 - 1s - loss: 0.4025 - accuracy: 0.8357 - 889ms/epoch - 1ms/step\n",
            "Epoch 35/200\n",
            "800/800 - 1s - loss: 0.4022 - accuracy: 0.8356 - 912ms/epoch - 1ms/step\n",
            "Epoch 36/200\n",
            "800/800 - 1s - loss: 0.4023 - accuracy: 0.8359 - 957ms/epoch - 1ms/step\n",
            "Epoch 37/200\n",
            "800/800 - 1s - loss: 0.4019 - accuracy: 0.8369 - 898ms/epoch - 1ms/step\n",
            "Epoch 38/200\n",
            "800/800 - 1s - loss: 0.4022 - accuracy: 0.8369 - 900ms/epoch - 1ms/step\n",
            "Epoch 39/200\n",
            "800/800 - 1s - loss: 0.4017 - accuracy: 0.8361 - 914ms/epoch - 1ms/step\n",
            "Epoch 40/200\n",
            "800/800 - 1s - loss: 0.4017 - accuracy: 0.8359 - 898ms/epoch - 1ms/step\n",
            "Epoch 41/200\n",
            "800/800 - 1s - loss: 0.4018 - accuracy: 0.8380 - 912ms/epoch - 1ms/step\n",
            "Epoch 42/200\n",
            "800/800 - 1s - loss: 0.4016 - accuracy: 0.8355 - 893ms/epoch - 1ms/step\n",
            "Epoch 43/200\n",
            "800/800 - 1s - loss: 0.4013 - accuracy: 0.8357 - 916ms/epoch - 1ms/step\n",
            "Epoch 44/200\n",
            "800/800 - 1s - loss: 0.4011 - accuracy: 0.8364 - 897ms/epoch - 1ms/step\n",
            "Epoch 45/200\n",
            "800/800 - 1s - loss: 0.4017 - accuracy: 0.8371 - 901ms/epoch - 1ms/step\n",
            "Epoch 46/200\n",
            "800/800 - 1s - loss: 0.4013 - accuracy: 0.8363 - 900ms/epoch - 1ms/step\n",
            "Epoch 47/200\n",
            "800/800 - 1s - loss: 0.4017 - accuracy: 0.8375 - 906ms/epoch - 1ms/step\n",
            "Epoch 48/200\n",
            "800/800 - 1s - loss: 0.4014 - accuracy: 0.8379 - 904ms/epoch - 1ms/step\n",
            "Epoch 49/200\n",
            "800/800 - 1s - loss: 0.4015 - accuracy: 0.8359 - 921ms/epoch - 1ms/step\n",
            "Epoch 50/200\n",
            "800/800 - 1s - loss: 0.4012 - accuracy: 0.8347 - 904ms/epoch - 1ms/step\n",
            "Epoch 51/200\n",
            "800/800 - 1s - loss: 0.4011 - accuracy: 0.8374 - 907ms/epoch - 1ms/step\n",
            "Epoch 52/200\n",
            "800/800 - 1s - loss: 0.4013 - accuracy: 0.8359 - 903ms/epoch - 1ms/step\n",
            "Epoch 53/200\n",
            "800/800 - 1s - loss: 0.4012 - accuracy: 0.8346 - 913ms/epoch - 1ms/step\n",
            "Epoch 54/200\n",
            "800/800 - 1s - loss: 0.4009 - accuracy: 0.8364 - 914ms/epoch - 1ms/step\n",
            "Epoch 55/200\n",
            "800/800 - 1s - loss: 0.4013 - accuracy: 0.8376 - 905ms/epoch - 1ms/step\n",
            "Epoch 56/200\n",
            "800/800 - 1s - loss: 0.4011 - accuracy: 0.8370 - 874ms/epoch - 1ms/step\n",
            "Epoch 57/200\n",
            "800/800 - 1s - loss: 0.4006 - accuracy: 0.8371 - 889ms/epoch - 1ms/step\n",
            "Epoch 58/200\n",
            "800/800 - 1s - loss: 0.4007 - accuracy: 0.8380 - 892ms/epoch - 1ms/step\n",
            "Epoch 59/200\n",
            "800/800 - 1s - loss: 0.4011 - accuracy: 0.8364 - 921ms/epoch - 1ms/step\n",
            "Epoch 60/200\n",
            "800/800 - 1s - loss: 0.4009 - accuracy: 0.8370 - 923ms/epoch - 1ms/step\n",
            "Epoch 61/200\n",
            "800/800 - 1s - loss: 0.4004 - accuracy: 0.8354 - 904ms/epoch - 1ms/step\n",
            "Epoch 62/200\n",
            "800/800 - 1s - loss: 0.4009 - accuracy: 0.8363 - 903ms/epoch - 1ms/step\n",
            "Epoch 63/200\n",
            "800/800 - 1s - loss: 0.4007 - accuracy: 0.8360 - 912ms/epoch - 1ms/step\n",
            "Epoch 64/200\n",
            "800/800 - 1s - loss: 0.4005 - accuracy: 0.8354 - 911ms/epoch - 1ms/step\n",
            "Epoch 65/200\n",
            "800/800 - 1s - loss: 0.4007 - accuracy: 0.8375 - 879ms/epoch - 1ms/step\n",
            "Epoch 66/200\n",
            "800/800 - 1s - loss: 0.4008 - accuracy: 0.8382 - 915ms/epoch - 1ms/step\n",
            "Epoch 67/200\n",
            "800/800 - 1s - loss: 0.4010 - accuracy: 0.8365 - 891ms/epoch - 1ms/step\n",
            "Epoch 68/200\n",
            "800/800 - 1s - loss: 0.4009 - accuracy: 0.8367 - 910ms/epoch - 1ms/step\n",
            "Epoch 69/200\n",
            "800/800 - 1s - loss: 0.4008 - accuracy: 0.8356 - 888ms/epoch - 1ms/step\n",
            "Epoch 70/200\n",
            "800/800 - 1s - loss: 0.4007 - accuracy: 0.8370 - 907ms/epoch - 1ms/step\n",
            "Epoch 71/200\n",
            "800/800 - 1s - loss: 0.4006 - accuracy: 0.8359 - 913ms/epoch - 1ms/step\n",
            "Epoch 72/200\n",
            "800/800 - 1s - loss: 0.4009 - accuracy: 0.8357 - 911ms/epoch - 1ms/step\n",
            "Epoch 73/200\n",
            "800/800 - 1s - loss: 0.4004 - accuracy: 0.8366 - 880ms/epoch - 1ms/step\n",
            "Epoch 74/200\n",
            "800/800 - 1s - loss: 0.4007 - accuracy: 0.8354 - 892ms/epoch - 1ms/step\n",
            "Epoch 75/200\n",
            "800/800 - 1s - loss: 0.4005 - accuracy: 0.8370 - 892ms/epoch - 1ms/step\n",
            "Epoch 76/200\n",
            "800/800 - 1s - loss: 0.4002 - accuracy: 0.8361 - 904ms/epoch - 1ms/step\n",
            "Epoch 77/200\n",
            "800/800 - 1s - loss: 0.4007 - accuracy: 0.8356 - 900ms/epoch - 1ms/step\n",
            "Epoch 78/200\n",
            "800/800 - 1s - loss: 0.4004 - accuracy: 0.8360 - 889ms/epoch - 1ms/step\n",
            "Epoch 79/200\n",
            "800/800 - 1s - loss: 0.4003 - accuracy: 0.8372 - 902ms/epoch - 1ms/step\n",
            "Epoch 80/200\n",
            "800/800 - 1s - loss: 0.4003 - accuracy: 0.8371 - 890ms/epoch - 1ms/step\n",
            "Epoch 81/200\n",
            "800/800 - 1s - loss: 0.4002 - accuracy: 0.8360 - 909ms/epoch - 1ms/step\n",
            "Epoch 82/200\n",
            "800/800 - 1s - loss: 0.4004 - accuracy: 0.8364 - 888ms/epoch - 1ms/step\n",
            "Epoch 83/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8382 - 921ms/epoch - 1ms/step\n",
            "Epoch 84/200\n",
            "800/800 - 1s - loss: 0.4000 - accuracy: 0.8370 - 899ms/epoch - 1ms/step\n",
            "Epoch 85/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8370 - 899ms/epoch - 1ms/step\n",
            "Epoch 86/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8363 - 888ms/epoch - 1ms/step\n",
            "Epoch 87/200\n",
            "800/800 - 1s - loss: 0.4000 - accuracy: 0.8361 - 910ms/epoch - 1ms/step\n",
            "Epoch 88/200\n",
            "800/800 - 1s - loss: 0.4003 - accuracy: 0.8361 - 912ms/epoch - 1ms/step\n",
            "Epoch 89/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8370 - 897ms/epoch - 1ms/step\n",
            "Epoch 90/200\n",
            "800/800 - 1s - loss: 0.3999 - accuracy: 0.8379 - 908ms/epoch - 1ms/step\n",
            "Epoch 91/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8347 - 877ms/epoch - 1ms/step\n",
            "Epoch 92/200\n",
            "800/800 - 1s - loss: 0.4002 - accuracy: 0.8366 - 890ms/epoch - 1ms/step\n",
            "Epoch 93/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8357 - 897ms/epoch - 1ms/step\n",
            "Epoch 94/200\n",
            "800/800 - 1s - loss: 0.3998 - accuracy: 0.8378 - 908ms/epoch - 1ms/step\n",
            "Epoch 95/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8364 - 883ms/epoch - 1ms/step\n",
            "Epoch 96/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8357 - 880ms/epoch - 1ms/step\n",
            "Epoch 97/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8361 - 879ms/epoch - 1ms/step\n",
            "Epoch 98/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8376 - 875ms/epoch - 1ms/step\n",
            "Epoch 99/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8380 - 892ms/epoch - 1ms/step\n",
            "Epoch 100/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8361 - 892ms/epoch - 1ms/step\n",
            "Epoch 101/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8370 - 897ms/epoch - 1ms/step\n",
            "Epoch 102/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8376 - 906ms/epoch - 1ms/step\n",
            "Epoch 103/200\n",
            "800/800 - 1s - loss: 0.3998 - accuracy: 0.8359 - 899ms/epoch - 1ms/step\n",
            "Epoch 104/200\n",
            "800/800 - 1s - loss: 0.3998 - accuracy: 0.8370 - 869ms/epoch - 1ms/step\n",
            "Epoch 105/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8364 - 914ms/epoch - 1ms/step\n",
            "Epoch 106/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8372 - 890ms/epoch - 1ms/step\n",
            "Epoch 107/200\n",
            "800/800 - 1s - loss: 0.3999 - accuracy: 0.8360 - 894ms/epoch - 1ms/step\n",
            "Epoch 108/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8374 - 911ms/epoch - 1ms/step\n",
            "Epoch 109/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8379 - 912ms/epoch - 1ms/step\n",
            "Epoch 110/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8372 - 906ms/epoch - 1ms/step\n",
            "Epoch 111/200\n",
            "800/800 - 1s - loss: 0.3998 - accuracy: 0.8381 - 891ms/epoch - 1ms/step\n",
            "Epoch 112/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8382 - 892ms/epoch - 1ms/step\n",
            "Epoch 113/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8369 - 894ms/epoch - 1ms/step\n",
            "Epoch 114/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8380 - 887ms/epoch - 1ms/step\n",
            "Epoch 115/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8361 - 908ms/epoch - 1ms/step\n",
            "Epoch 116/200\n",
            "800/800 - 1s - loss: 0.4001 - accuracy: 0.8380 - 904ms/epoch - 1ms/step\n",
            "Epoch 117/200\n",
            "800/800 - 1s - loss: 0.4000 - accuracy: 0.8367 - 928ms/epoch - 1ms/step\n",
            "Epoch 118/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8357 - 913ms/epoch - 1ms/step\n",
            "Epoch 119/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8374 - 907ms/epoch - 1ms/step\n",
            "Epoch 120/200\n",
            "800/800 - 2s - loss: 0.3996 - accuracy: 0.8385 - 2s/epoch - 2ms/step\n",
            "Epoch 121/200\n",
            "800/800 - 1s - loss: 0.3999 - accuracy: 0.8375 - 913ms/epoch - 1ms/step\n",
            "Epoch 122/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8374 - 878ms/epoch - 1ms/step\n",
            "Epoch 123/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8389 - 902ms/epoch - 1ms/step\n",
            "Epoch 124/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8371 - 888ms/epoch - 1ms/step\n",
            "Epoch 125/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8365 - 892ms/epoch - 1ms/step\n",
            "Epoch 126/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8376 - 905ms/epoch - 1ms/step\n",
            "Epoch 127/200\n",
            "800/800 - 1s - loss: 0.3998 - accuracy: 0.8371 - 916ms/epoch - 1ms/step\n",
            "Epoch 128/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8364 - 899ms/epoch - 1ms/step\n",
            "Epoch 129/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8371 - 904ms/epoch - 1ms/step\n",
            "Epoch 130/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8366 - 929ms/epoch - 1ms/step\n",
            "Epoch 131/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8381 - 903ms/epoch - 1ms/step\n",
            "Epoch 132/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8370 - 897ms/epoch - 1ms/step\n",
            "Epoch 133/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8366 - 896ms/epoch - 1ms/step\n",
            "Epoch 134/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8393 - 895ms/epoch - 1ms/step\n",
            "Epoch 135/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8382 - 898ms/epoch - 1ms/step\n",
            "Epoch 136/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8380 - 891ms/epoch - 1ms/step\n",
            "Epoch 137/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8375 - 887ms/epoch - 1ms/step\n",
            "Epoch 138/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8357 - 911ms/epoch - 1ms/step\n",
            "Epoch 139/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8367 - 928ms/epoch - 1ms/step\n",
            "Epoch 140/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8382 - 881ms/epoch - 1ms/step\n",
            "Epoch 141/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8372 - 900ms/epoch - 1ms/step\n",
            "Epoch 142/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8363 - 897ms/epoch - 1ms/step\n",
            "Epoch 143/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8370 - 901ms/epoch - 1ms/step\n",
            "Epoch 144/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8374 - 904ms/epoch - 1ms/step\n",
            "Epoch 145/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8385 - 900ms/epoch - 1ms/step\n",
            "Epoch 146/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8360 - 900ms/epoch - 1ms/step\n",
            "Epoch 147/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8357 - 906ms/epoch - 1ms/step\n",
            "Epoch 148/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8382 - 895ms/epoch - 1ms/step\n",
            "Epoch 149/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8393 - 889ms/epoch - 1ms/step\n",
            "Epoch 150/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8376 - 917ms/epoch - 1ms/step\n",
            "Epoch 151/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8375 - 914ms/epoch - 1ms/step\n",
            "Epoch 152/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8380 - 894ms/epoch - 1ms/step\n",
            "Epoch 153/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8376 - 907ms/epoch - 1ms/step\n",
            "Epoch 154/200\n",
            "800/800 - 1s - loss: 0.3998 - accuracy: 0.8380 - 896ms/epoch - 1ms/step\n",
            "Epoch 155/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8367 - 892ms/epoch - 1ms/step\n",
            "Epoch 156/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8381 - 918ms/epoch - 1ms/step\n",
            "Epoch 157/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8367 - 911ms/epoch - 1ms/step\n",
            "Epoch 158/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8369 - 891ms/epoch - 1ms/step\n",
            "Epoch 159/200\n",
            "800/800 - 1s - loss: 0.3988 - accuracy: 0.8371 - 889ms/epoch - 1ms/step\n",
            "Epoch 160/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8384 - 898ms/epoch - 1ms/step\n",
            "Epoch 161/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8374 - 919ms/epoch - 1ms/step\n",
            "Epoch 162/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8359 - 913ms/epoch - 1ms/step\n",
            "Epoch 163/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8370 - 904ms/epoch - 1ms/step\n",
            "Epoch 164/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8370 - 901ms/epoch - 1ms/step\n",
            "Epoch 165/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8382 - 906ms/epoch - 1ms/step\n",
            "Epoch 166/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8369 - 901ms/epoch - 1ms/step\n",
            "Epoch 167/200\n",
            "800/800 - 1s - loss: 0.3997 - accuracy: 0.8365 - 914ms/epoch - 1ms/step\n",
            "Epoch 168/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8372 - 945ms/epoch - 1ms/step\n",
            "Epoch 169/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8364 - 906ms/epoch - 1ms/step\n",
            "Epoch 170/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8379 - 905ms/epoch - 1ms/step\n",
            "Epoch 171/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8376 - 898ms/epoch - 1ms/step\n",
            "Epoch 172/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8359 - 890ms/epoch - 1ms/step\n",
            "Epoch 173/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8376 - 922ms/epoch - 1ms/step\n",
            "Epoch 174/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8376 - 895ms/epoch - 1ms/step\n",
            "Epoch 175/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8363 - 896ms/epoch - 1ms/step\n",
            "Epoch 176/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8365 - 879ms/epoch - 1ms/step\n",
            "Epoch 177/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8374 - 910ms/epoch - 1ms/step\n",
            "Epoch 178/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8359 - 906ms/epoch - 1ms/step\n",
            "Epoch 179/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8376 - 920ms/epoch - 1ms/step\n",
            "Epoch 180/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8376 - 898ms/epoch - 1ms/step\n",
            "Epoch 181/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8367 - 918ms/epoch - 1ms/step\n",
            "Epoch 182/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8370 - 909ms/epoch - 1ms/step\n",
            "Epoch 183/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8365 - 914ms/epoch - 1ms/step\n",
            "Epoch 184/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8371 - 927ms/epoch - 1ms/step\n",
            "Epoch 185/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8363 - 908ms/epoch - 1ms/step\n",
            "Epoch 186/200\n",
            "800/800 - 1s - loss: 0.3987 - accuracy: 0.8372 - 891ms/epoch - 1ms/step\n",
            "Epoch 187/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8370 - 917ms/epoch - 1ms/step\n",
            "Epoch 188/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8370 - 902ms/epoch - 1ms/step\n",
            "Epoch 189/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8374 - 907ms/epoch - 1ms/step\n",
            "Epoch 190/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8372 - 924ms/epoch - 1ms/step\n",
            "Epoch 191/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8378 - 932ms/epoch - 1ms/step\n",
            "Epoch 192/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8384 - 908ms/epoch - 1ms/step\n",
            "Epoch 193/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8363 - 909ms/epoch - 1ms/step\n",
            "Epoch 194/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8384 - 904ms/epoch - 1ms/step\n",
            "Epoch 195/200\n",
            "800/800 - 1s - loss: 0.3990 - accuracy: 0.8375 - 911ms/epoch - 1ms/step\n",
            "Epoch 196/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8355 - 897ms/epoch - 1ms/step\n",
            "Epoch 197/200\n",
            "800/800 - 1s - loss: 0.3988 - accuracy: 0.8367 - 904ms/epoch - 1ms/step\n",
            "Epoch 198/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8371 - 916ms/epoch - 1ms/step\n",
            "Epoch 199/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8371 - 916ms/epoch - 1ms/step\n",
            "Epoch 200/200\n",
            "800/800 - 1s - loss: 0.3992 - accuracy: 0.8380 - 897ms/epoch - 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation - loss will be higher, accuracy will be lower\n",
        "loss, accuracy = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxvropAwi8FM",
        "outputId": "8ccbd6d4-251b-4cce-ce5a-a32847cb2f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcr_TNwWjiBU",
        "outputId": "80ded038-fb56-47c0-a22c-1b6844038cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       ...,\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "zBpcqvJFjcT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict using the info of a new customer\n",
        "\n",
        "new_customer = [[0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]\n",
        "new_customer = sc.transform(new_customer)\n",
        "new_prediction = model.predict(new_customer)\n",
        "new_prediction = (new_prediction > 0.5)\n",
        "\n",
        "new_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njJoJv1YjvyM",
        "outputId": "f15debca-66e7-47cb-e7ad-f7368ef297f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'loss'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8ILXiCXMkW8K",
        "outputId": "3bcf3a62-528b-4a33-c63d-c5b96e5efaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#An alternative to using train_test_split() is to specify a validation_split percentage\n",
        "#This is done when fitting the model, for example:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)\n",
        "\n",
        "history = model.fit(x, y, verbose = 1, validation_split=0.2, epochs = 100, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkWcZ_MJli0Q",
        "outputId": "28713ca7-1878-465b-dbce-6231987f93ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3962 - accuracy: 0.8385 - val_loss: 0.4071 - val_accuracy: 0.8350\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3963 - accuracy: 0.8378 - val_loss: 0.4067 - val_accuracy: 0.8330\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3962 - accuracy: 0.8372 - val_loss: 0.4079 - val_accuracy: 0.8310\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3963 - accuracy: 0.8386 - val_loss: 0.4066 - val_accuracy: 0.8315\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3957 - accuracy: 0.8378 - val_loss: 0.4075 - val_accuracy: 0.8325\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3959 - accuracy: 0.8360 - val_loss: 0.4069 - val_accuracy: 0.8320\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3955 - accuracy: 0.8369 - val_loss: 0.4069 - val_accuracy: 0.8315\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3958 - accuracy: 0.8372 - val_loss: 0.4082 - val_accuracy: 0.8330\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3957 - accuracy: 0.8378 - val_loss: 0.4073 - val_accuracy: 0.8340\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3958 - accuracy: 0.8371 - val_loss: 0.4080 - val_accuracy: 0.8285\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3958 - accuracy: 0.8372 - val_loss: 0.4086 - val_accuracy: 0.8320\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3953 - accuracy: 0.8386 - val_loss: 0.4088 - val_accuracy: 0.8315\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3958 - accuracy: 0.8381 - val_loss: 0.4089 - val_accuracy: 0.8340\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3954 - accuracy: 0.8389 - val_loss: 0.4086 - val_accuracy: 0.8290\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3950 - accuracy: 0.8365 - val_loss: 0.4084 - val_accuracy: 0.8295\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3952 - accuracy: 0.8380 - val_loss: 0.4099 - val_accuracy: 0.8310\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3951 - accuracy: 0.8399 - val_loss: 0.4102 - val_accuracy: 0.8355\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3955 - accuracy: 0.8382 - val_loss: 0.4091 - val_accuracy: 0.8315\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3951 - accuracy: 0.8363 - val_loss: 0.4087 - val_accuracy: 0.8340\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3950 - accuracy: 0.8372 - val_loss: 0.4099 - val_accuracy: 0.8315\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3953 - accuracy: 0.8382 - val_loss: 0.4091 - val_accuracy: 0.8280\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3948 - accuracy: 0.8382 - val_loss: 0.4104 - val_accuracy: 0.8305\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3952 - accuracy: 0.8391 - val_loss: 0.4086 - val_accuracy: 0.8325\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3949 - accuracy: 0.8382 - val_loss: 0.4112 - val_accuracy: 0.8245\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3953 - accuracy: 0.8374 - val_loss: 0.4103 - val_accuracy: 0.8285\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3951 - accuracy: 0.8381 - val_loss: 0.4097 - val_accuracy: 0.8305\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3953 - accuracy: 0.8382 - val_loss: 0.4117 - val_accuracy: 0.8270\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3951 - accuracy: 0.8382 - val_loss: 0.4101 - val_accuracy: 0.8320\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3948 - accuracy: 0.8370 - val_loss: 0.4110 - val_accuracy: 0.8320\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3949 - accuracy: 0.8389 - val_loss: 0.4108 - val_accuracy: 0.8340\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3953 - accuracy: 0.8394 - val_loss: 0.4093 - val_accuracy: 0.8300\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3952 - accuracy: 0.8379 - val_loss: 0.4095 - val_accuracy: 0.8295\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3947 - accuracy: 0.8370 - val_loss: 0.4096 - val_accuracy: 0.8335\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3952 - accuracy: 0.8389 - val_loss: 0.4096 - val_accuracy: 0.8315\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3951 - accuracy: 0.8378 - val_loss: 0.4111 - val_accuracy: 0.8285\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3953 - accuracy: 0.8389 - val_loss: 0.4109 - val_accuracy: 0.8345\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3954 - accuracy: 0.8376 - val_loss: 0.4094 - val_accuracy: 0.8315\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3949 - accuracy: 0.8389 - val_loss: 0.4091 - val_accuracy: 0.8290\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3949 - accuracy: 0.8376 - val_loss: 0.4092 - val_accuracy: 0.8330\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3952 - accuracy: 0.8372 - val_loss: 0.4124 - val_accuracy: 0.8280\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3953 - accuracy: 0.8390 - val_loss: 0.4096 - val_accuracy: 0.8340\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8374 - val_loss: 0.4100 - val_accuracy: 0.8295\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8385 - val_loss: 0.4101 - val_accuracy: 0.8280\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8391 - val_loss: 0.4089 - val_accuracy: 0.8300\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8396 - val_loss: 0.4103 - val_accuracy: 0.8270\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8379 - val_loss: 0.4102 - val_accuracy: 0.8315\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8379 - val_loss: 0.4096 - val_accuracy: 0.8310\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3946 - accuracy: 0.8388 - val_loss: 0.4106 - val_accuracy: 0.8290\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3953 - accuracy: 0.8379 - val_loss: 0.4094 - val_accuracy: 0.8335\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8393 - val_loss: 0.4112 - val_accuracy: 0.8285\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8385 - val_loss: 0.4101 - val_accuracy: 0.8335\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8378 - val_loss: 0.4101 - val_accuracy: 0.8295\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8386 - val_loss: 0.4110 - val_accuracy: 0.8305\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3949 - accuracy: 0.8375 - val_loss: 0.4097 - val_accuracy: 0.8300\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8378 - val_loss: 0.4108 - val_accuracy: 0.8270\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8389 - val_loss: 0.4100 - val_accuracy: 0.8305\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3946 - accuracy: 0.8380 - val_loss: 0.4106 - val_accuracy: 0.8305\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8386 - val_loss: 0.4108 - val_accuracy: 0.8305\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3953 - accuracy: 0.8384 - val_loss: 0.4104 - val_accuracy: 0.8340\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8399 - val_loss: 0.4108 - val_accuracy: 0.8345\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8375 - val_loss: 0.4105 - val_accuracy: 0.8270\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8386 - val_loss: 0.4103 - val_accuracy: 0.8300\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8389 - val_loss: 0.4098 - val_accuracy: 0.8315\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8389 - val_loss: 0.4131 - val_accuracy: 0.8260\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8357 - val_loss: 0.4099 - val_accuracy: 0.8305\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8380 - val_loss: 0.4102 - val_accuracy: 0.8300\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8388 - val_loss: 0.4112 - val_accuracy: 0.8285\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3952 - accuracy: 0.8389 - val_loss: 0.4102 - val_accuracy: 0.8285\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.8393 - val_loss: 0.4098 - val_accuracy: 0.8345\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3952 - accuracy: 0.8372 - val_loss: 0.4103 - val_accuracy: 0.8295\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3941 - accuracy: 0.8391 - val_loss: 0.4105 - val_accuracy: 0.8310\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3947 - accuracy: 0.8365 - val_loss: 0.4100 - val_accuracy: 0.8290\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3947 - accuracy: 0.8386 - val_loss: 0.4119 - val_accuracy: 0.8315\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3952 - accuracy: 0.8375 - val_loss: 0.4103 - val_accuracy: 0.8300\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8406 - val_loss: 0.4114 - val_accuracy: 0.8290\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8385 - val_loss: 0.4110 - val_accuracy: 0.8315\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8381 - val_loss: 0.4121 - val_accuracy: 0.8280\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3947 - accuracy: 0.8384 - val_loss: 0.4100 - val_accuracy: 0.8310\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8385 - val_loss: 0.4102 - val_accuracy: 0.8335\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3949 - accuracy: 0.8384 - val_loss: 0.4109 - val_accuracy: 0.8290\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.8382 - val_loss: 0.4106 - val_accuracy: 0.8320\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3951 - accuracy: 0.8388 - val_loss: 0.4100 - val_accuracy: 0.8295\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3948 - accuracy: 0.8376 - val_loss: 0.4095 - val_accuracy: 0.8315\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3947 - accuracy: 0.8389 - val_loss: 0.4101 - val_accuracy: 0.8300\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3950 - accuracy: 0.8380 - val_loss: 0.4107 - val_accuracy: 0.8275\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8384 - val_loss: 0.4095 - val_accuracy: 0.8295\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3944 - accuracy: 0.8393 - val_loss: 0.4106 - val_accuracy: 0.8320\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3947 - accuracy: 0.8391 - val_loss: 0.4131 - val_accuracy: 0.8325\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8379 - val_loss: 0.4118 - val_accuracy: 0.8310\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3949 - accuracy: 0.8395 - val_loss: 0.4103 - val_accuracy: 0.8320\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3949 - accuracy: 0.8396 - val_loss: 0.4107 - val_accuracy: 0.8265\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3944 - accuracy: 0.8385 - val_loss: 0.4102 - val_accuracy: 0.8285\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3943 - accuracy: 0.8370 - val_loss: 0.4111 - val_accuracy: 0.8325\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8382 - val_loss: 0.4119 - val_accuracy: 0.8270\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3950 - accuracy: 0.8370 - val_loss: 0.4107 - val_accuracy: 0.8305\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8384 - val_loss: 0.4099 - val_accuracy: 0.8290\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3946 - accuracy: 0.8385 - val_loss: 0.4112 - val_accuracy: 0.8340\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8385 - val_loss: 0.4111 - val_accuracy: 0.8340\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3950 - accuracy: 0.8381 - val_loss: 0.4115 - val_accuracy: 0.8295\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.3946 - accuracy: 0.8386 - val_loss: 0.4114 - val_accuracy: 0.8285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'val_accuracy', 'loss', 'val_loss'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "de8379d2-c4aa-4c13-fdef-7999647cc3c8",
        "id": "FN00LtjnmeOY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model in H5 format"
      ],
      "metadata": {
        "id": "5pA3-BpPnWqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/ANN_test_data/churn_model.h5')"
      ],
      "metadata": {
        "id": "j3VRq-QJncpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to load the model again:\n",
        "my_trained_model = keras.model.load('/content/drive/MyDrive/Colab Notebooks/ANN_test_data/churn_model.h5')"
      ],
      "metadata": {
        "id": "DP4RUkHDnzQv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}